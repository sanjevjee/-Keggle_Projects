{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz64hrUSlxi4"
      },
      "source": [
        "<center><font size=6>Wind Turbine Generator Failure Prediction</font></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EaJ8AGwpM-2"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3-QehJxbp0t"
      },
      "source": [
        "### Business Context\n",
        "\n",
        "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.\n",
        "\n",
        "Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.\n",
        "\n",
        "Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.\n",
        "\n",
        "The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.).\n",
        "\n",
        "\n",
        "\n",
        "### Objective\n",
        "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.\n",
        "\n",
        "The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost.\n",
        "The nature of predictions made by the classification model will translate as follows:\n",
        "\n",
        "- True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.\n",
        "- False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.\n",
        "- False positives (FP) are detections where there is no failure. These will result in inspection costs.\n",
        "\n",
        "It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.\n",
        "\n",
        "“1” in the target variables should be considered as “failure” and “0” represents “No failure”.\n",
        "\n",
        "### Data Description\n",
        "- The data provided is a transformed version of original data which was collected using sensors.\n",
        "- Train.csv - To be used for training and tuning of models.\n",
        "- Test.csv - To be used only for testing the performance of the final best model.\n",
        "- Both the datasets consist of 40 predictor variables and 1 target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_-uuGqH-qTt"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uSoJ9UAk5Py"
      },
      "outputs": [],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "!pip install pandas==1.5.3 numpy==1.25.2 matplotlib==3.7.1 seaborn==0.13.1 scikit-learn==1.2.2 imbalanced-learn==0.10.1 xgboost==2.0.3 threadpoolctl==3.3.0 -q --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEGFqY5Zl0My"
      },
      "source": [
        "**Note:** After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbiVVX6hbp0v"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# To tune model, get different metric scores, and split data\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "\n",
        "# To be used for data scaling and one hot encoding\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# To impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# To oversample and undersample data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# To do hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# To be used for creating pipelines and personalizing them\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# To define maximum number of columns to be displayed in a dataframe\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "\n",
        "# To supress scientific notations for a dataframe\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To help with model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    BaggingClassifier,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# To suppress scientific notations\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To suppress warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment and run the following lines for Google Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D4QgYmaOkMEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39UgpBY3bp0y"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Train.csv\")\n",
        "df_test = pd.read_csv(\"Test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cVx5kZHbp02"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-5jUOgu-qTz"
      },
      "source": [
        "The initial steps to get an overview of any dataset is to:\n",
        "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- get information about the number of rows and columns in the dataset\n",
        "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQi5ygTC-qT1"
      },
      "source": [
        "### Checking the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y8epHpjbp0z"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the training data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_9AEGLbp00"
      },
      "source": [
        "* The training dataset has 20000 rows and 41 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA15qTjzbp01"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the test data\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzGT-Tbfbp02"
      },
      "source": [
        "* The test dataset has 5000 rows and 41 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTsYJZBubp02"
      },
      "outputs": [],
      "source": [
        "# let's create a copy of the training data\n",
        "data = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69ImWbLXbp03"
      },
      "outputs": [],
      "source": [
        "# let's create a copy of the training data\n",
        "data_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlzqMR1K-qTz"
      },
      "source": [
        "### Displaying the first few rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9RnN7Twbp03"
      },
      "outputs": [],
      "source": [
        "# let's view the first 5 rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "961px703qhLV"
      },
      "source": [
        "### Displaying the first few rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Ir8YPgbp04"
      },
      "outputs": [],
      "source": [
        "# let's view the last 5 rows of the data\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TcqcxbK-qT3"
      },
      "source": [
        "### Checking the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXBYJoKkbp04"
      },
      "outputs": [],
      "source": [
        "# let's check the data types of the columns in the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvN3_-Vdbp04"
      },
      "source": [
        "- All the variables in the data are of type float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNr4bWoM-qT5"
      },
      "source": [
        "### Checking for duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0EmBHNmbp04"
      },
      "outputs": [],
      "source": [
        "# let's check for duplicate values in the data\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbCYiLWheK8B"
      },
      "source": [
        "- No duplicate values present in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch_TjRfF-qT5"
      },
      "source": [
        "### Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlwFZm-Jbp05"
      },
      "outputs": [],
      "source": [
        "# let's check for missing values in the data\n",
        "round(data.isnull().sum() / data.isnull().count() * 100, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkONaMVubp05"
      },
      "source": [
        "- There are 0.090% missing values in V1 and 0.090% missing values in V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33bar6robp06"
      },
      "outputs": [],
      "source": [
        "# let's check for missing values in the test data\n",
        "round(data_test.isnull().sum() / data_test.isnull().count() * 100, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3CsRJ5bp06"
      },
      "source": [
        "- There are 0.1% missing values in V1 and 0.12% missing values in V2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCorhch-qT4"
      },
      "source": [
        "### Statistical summary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J6lzvHKCbp06"
      },
      "outputs": [],
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3JYKVQubp06"
      },
      "source": [
        "#### Observations:\n",
        "- Values of all the variables lies between -25 and 25\n",
        "- Looking at the values of 75th percentile and maximum, we can see there are outliers in many variables like V1, V2 and many more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPuzWO7hmV8"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv7Bs8aUbp07"
      },
      "source": [
        "### Univariate analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QIP4bI3Zbp07"
      },
      "outputs": [],
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p0ip-InCbp07",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for feature in df.columns:\n",
        "    histogram_boxplot(df, feature, figsize=(12, 7), kde=False, bins=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT6jiV1-bp07"
      },
      "source": [
        "- All the variables are normally distributed\n",
        "- This distribution might not be true for original data but since the provided data is ciphered, this kind of trend in distribution is possible - maybe the original data was transformed to normally distributed data.\n",
        "- The outliers visible through boxplots are not incorrect readings, the values might be like this only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CjaGOdvbp08"
      },
      "source": [
        "### Let's look at the values in target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jchAb6Ikbp08"
      },
      "outputs": [],
      "source": [
        "df[\"Target\"].value_counts(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5rupsM4sbp08"
      },
      "outputs": [],
      "source": [
        "df_test[\"Target\"].value_counts(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJk0v4O-bp08"
      },
      "source": [
        "- The distribution of 0s and 1s is the same in both Train and Test sets.\n",
        "- 94.5% of the observations are negative and only 5.5% of the observations are a positive representing failure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp8vC9MZbp09"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMTLLop3yDwk"
      },
      "source": [
        "### Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C-xgnTbGb4CY"
      },
      "outputs": [],
      "source": [
        "# Dividing train data into X and y\n",
        "X = data.drop([\"Target\"], axis=1)\n",
        "y = data[\"Target\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBXiW4s4kd63"
      },
      "source": [
        "**Since we already have a separate test set, we don't need to divide data into train, valiation and test**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j-8vqBMXbp09"
      },
      "outputs": [],
      "source": [
        "# Splitting data into training and validation set:\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=1, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hIsrQQVqRbnY"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the X_train data\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o3_X_6ZicNfN"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the X_val data\n",
        "X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IktO9G2Lbp09"
      },
      "outputs": [],
      "source": [
        "# Dividing test data into X_test and y_test\n",
        "X_test = data_test.drop([\"Target\"], axis=1)\n",
        "y_test = data_test[\"Target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XmuB5K_9b8tP"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the X_test data\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIcs_56ECHk"
      },
      "source": [
        "### Missing value imputation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J99-7Kubp09"
      },
      "source": [
        "- There were few missing values in V1 and V2, we will impute them using the median.\n",
        "- And to avoid data leakage we will impute missing values after splitting train data into train and validation sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "28L1vgAwbp09"
      },
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FNfbw4rJbp09"
      },
      "outputs": [],
      "source": [
        "# Fit and transform the train data\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "\n",
        "# Transform the validation data\n",
        "X_val = pd.DataFrame(imputer.transform(X_val), columns=X_train.columns)\n",
        "\n",
        "# Transform the test data\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3jdLvwTAbp09"
      },
      "outputs": [],
      "source": [
        "# Checking that no column has missing values in train or test sets\n",
        "print(X_train.isna().sum())\n",
        "print(\"-\" * 30)\n",
        "print(X_val.isna().sum())\n",
        "print(\"-\" * 30)\n",
        "print(X_test.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3R6Ky7bp0-"
      },
      "source": [
        "- All the missing values have been imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOa9FGA6WtG"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czwxDIZNccQL"
      },
      "source": [
        "### Model evaluation criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ORUgmUjDZC"
      },
      "source": [
        "The nature of predictions made by the classification model will translate as follows:\n",
        "\n",
        "- True positives (TP) are failures correctly predicted by the model.\n",
        "- False negatives (FN) are real failures in a generator where there is no detection by model.\n",
        "- False positives (FP) are failure detections in a generator where there is no failure.\n",
        "\n",
        "**Which metric to optimize?**\n",
        "\n",
        "* We need to choose the metric which will ensure that the maximum number of generator failures are predicted correctly by the model.\n",
        "* We would want Recall to be maximized as greater the Recall, the higher the chances of minimizing false negatives.\n",
        "* We want to minimize false negatives because if a model predicts that a machine will have no failure when there will be a failure, it will increase the maintenance cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUs837UXbp0-"
      },
      "source": [
        "**Let's define a function to output different metrics (including recall) on the train and test set and a function to show confusion matrix so that we do not have to use the same code repetitively while evaluating models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nt33nwx_bp0-"
      },
      "outputs": [],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    TP = confusion_matrix(target, model.predict(predictors))[1, 1]\n",
        "    FP = confusion_matrix(target, model.predict(predictors))[0, 1]\n",
        "    FN = confusion_matrix(target, model.predict(predictors))[1, 0]\n",
        "\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1,\n",
        "          },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QZZoxoDcoDm"
      },
      "source": [
        "### Defining scorer to be used for cross-validation and hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLUm-eSi_cJ"
      },
      "source": [
        "- We want to reduce false negatives and will try to maximize \"Recall\".\n",
        "- To maximize Recall, we can use Recall as a **scorer** in cross-validation and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fTqBmDuPm0hj"
      },
      "outputs": [],
      "source": [
        "scorer = metrics.make_scorer(metrics.recall_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWoHuUpjbp0_"
      },
      "source": [
        "**We are now done with pre-processing and evaluation criterion, so let's start building the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fI98GOV0pTY"
      },
      "source": [
        "### Model building with original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-OTOG3o1bp0_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
        "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "\n",
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train, y=y_train, scoring = scorer,cv=kfold\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cm61fR_mbp0_",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXcjw-yZbp1A"
      },
      "source": [
        "- Recall value is highest for Xgboost followed by Bagging Classifier,Random Forest, and Gradient Boosting Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORykimuM049i"
      },
      "source": [
        "**We can see the performance of models with original data, let's see if oversampling the data can help us improve the performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C91_6Swtbp1A"
      },
      "source": [
        "### Model Building with oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o2dEk01hbp1A"
      },
      "outputs": [],
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# Synthetic Minority Over Sampling Technique\n",
        "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
        "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_over == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_over == 0)))\n",
        "\n",
        "\n",
        "print(\"After OverSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
        "print(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZsOer36qbp1A"
      },
      "outputs": [],
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
        "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "\n",
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train_over, y=y_train_over,scoring = scorer, cv=kfold\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kwUcBORjbp1A",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oop_TKulbp1B"
      },
      "source": [
        "- Recall value is highest for Random Forest, Decision tree,and Bagging Classifier, but they are overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdf2AAG51AKG"
      },
      "source": [
        "**We can see that oversampling of data helped improve the performance a lot, now let's see how models perform with undersampled data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYLfDmHvbp1B"
      },
      "source": [
        "### Model Building with undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PHM-5g8Qbp1B"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
        "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "\n",
        "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_un == 1)))\n",
        "print(\"After UnderSampling, counts of label '0': {} \\n\".format(sum(y_train_un == 0)))\n",
        "\n",
        "\n",
        "print(\"After UnderSampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
        "print(\"After UnderSampling, the shape of train_y: {} \\n\".format(y_train_un.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rc5ndPMubp1B",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\",n_jobs=-1)))\n",
        "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "\n",
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train_un, y=y_train_un,scoring = scorer, cv=kfold,n_jobs =-1\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train_un, y_train_un)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8HcDqaD2bp1B",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4R_ceLhbp1B"
      },
      "source": [
        "- Recall value is highest for Random Forest followed by Xgboost model and Gradient Boosting .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLZlKa99bp1C"
      },
      "source": [
        "**After looking at performance of all the models, let's decide which models can further improve with hyperparameter tuning**\n",
        "\n",
        "- Recall value is highest for the following models:\n",
        "  - Random Forest with undersampled data\n",
        "  - Gradient Boosting with oversampled data\n",
        "  - AdaBoost on oversampled data\n",
        "  - Xgboost on oversampled data\n",
        "- So, we will tune these 4 models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg_OREBD1NOy"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FtmPS7Ubp1D"
      },
      "source": [
        "### Tuning AdaBoost using oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IPSlOlvkbp1D"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = AdaBoostClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 150, 200],\n",
        "    \"learning_rate\": [0.2, 0.05],\n",
        "    \"base_estimator\": [DecisionTreeClassifier(max_depth=1, random_state=1), DecisionTreeClassifier(max_depth=2, random_state=1), DecisionTreeClassifier(max_depth=3, random_state=1),\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over,y_train_over) ## Complete the code to fit the model on over sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xhrOotEVFuN8"
      },
      "outputs": [],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_ada = AdaBoostClassifier(\n",
        "    n_estimators= 200, learning_rate= 0.2, base_estimator= DecisionTreeClassifier(max_depth=3, random_state=1)\n",
        ")\n",
        "\n",
        "tuned_ada.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kGRRtFcsFxZD"
      },
      "outputs": [],
      "source": [
        "ada_train_perf = model_performance_classification_sklearn(tuned_ada, X_train_over, y_train_over)\n",
        "ada_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "10_dV5m4bp1D"
      },
      "outputs": [],
      "source": [
        "ada_val_perf = model_performance_classification_sklearn(tuned_ada, X_val, y_val)\n",
        "ada_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgeupaE43aAQ"
      },
      "source": [
        "- AdaBoost is slightly overfitting the train data but overall the performance has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqj6dc38bp1E"
      },
      "source": [
        "### Tuning Random forest using undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9tLNoDYhbp1E"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = RandomForestClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [200,250,300],\n",
        "    \"min_samples_leaf\": np.arange(1, 4),\n",
        "    \"max_features\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\n",
        "    \"max_samples\": np.arange(0.4, 0.7, 0.1)}\n",
        "\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_un,y_train_un) ## Complete the code to fit the model on under sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5kmoh9KMbp1E"
      },
      "outputs": [],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_rf2 = RandomForestClassifier(\n",
        "    max_features=\"sqrt\",\n",
        "    random_state=1,\n",
        "    max_samples=0.5,\n",
        "    n_estimators=300,\n",
        "    min_samples_leaf=2,\n",
        ")\n",
        "\n",
        "tuned_rf2.fit(X_train_un, y_train_un)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bAAD5mzybp1E"
      },
      "outputs": [],
      "source": [
        "rf2_train_perf = model_performance_classification_sklearn(\n",
        "    tuned_rf2, X_train_un, y_train_un\n",
        ")\n",
        "rf2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WTtYpzO-bp1E",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "rf2_val_perf = model_performance_classification_sklearn(tuned_rf2, X_val, y_val)\n",
        "rf2_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsF6TuIz3aAR"
      },
      "source": [
        "- Random forest classifier is slightly overfitting the train data but overall the performance has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uLE_tPV2Roq"
      },
      "source": [
        "### Tuning with Gradient boosting with oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ikBgsbjn2RHu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV\n",
        "param_grid={\"n_estimators\": np.arange(100,150,25), \"learning_rate\": [0.2, 0.05, 1], \"subsample\":[0.5,0.7], \"max_features\":[0.5,0.7]}\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, scoring=scorer, n_iter=50, n_jobs = -1, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over, y_train_over)\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o0sxrmnx2Q9S"
      },
      "outputs": [],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_gbm = GradientBoostingClassifier(\n",
        "    max_features=0.5,\n",
        "    random_state=1,\n",
        "    learning_rate=1,\n",
        "    n_estimators=125,\n",
        "    subsample=0.7\n",
        ")\n",
        "\n",
        "tuned_gbm.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fXkAXXum2Q0-"
      },
      "outputs": [],
      "source": [
        "gbm_train_perf = model_performance_classification_sklearn(\n",
        "    tuned_gbm, X_train_over, y_train_over\n",
        ")\n",
        "gbm_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZF3y7Jl12Qi-"
      },
      "outputs": [],
      "source": [
        "gbm_val_perf = model_performance_classification_sklearn(tuned_gbm, X_val, y_val)\n",
        "gbm_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npIQSIxGyhVM"
      },
      "source": [
        "- Gradient Boosting is slightly overfitting the train data but overall the performance has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbrQHwrKbp1C"
      },
      "source": [
        "### Tuning XGBoost using oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ec8e6iVzbp1C"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = XGBClassifier(random_state=1,eval_metric='logloss')\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV\n",
        "param_grid={'n_estimators':[150,200,250],'scale_pos_weight':[5,10], 'learning_rate':[0.1,0.2], 'gamma':[0,3,5], 'subsample':[0.8,0.9]}\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train_over,y_train_over)## Complete the code to fit the model on over sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NSio3khJbp1C",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "xgb2 = XGBClassifier(\n",
        "    random_state=1,\n",
        "    eval_metric=\"logloss\",\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=10,\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.2,\n",
        "    gamma=0,\n",
        ")\n",
        "\n",
        "xgb2.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hDzHR8Pwbp1D"
      },
      "outputs": [],
      "source": [
        "xgb2_train_perf = model_performance_classification_sklearn(\n",
        "    xgb2, X_train_over, y_train_over\n",
        ")\n",
        "xgb2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jiDRsOrMbp1D",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "xgb2_val_perf = model_performance_classification_sklearn(xgb2, X_val, y_val)\n",
        "xgb2_val_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4ohDWLJ3aAY"
      },
      "source": [
        "- Overfitting has further increased using oversampled data and the model is performing good on train data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fyp5xd91Z-W"
      },
      "source": [
        "**We have now tuned all the models, let's compare the performance of all tuned models and see which one is the best.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9JNnpxa4jau"
      },
      "source": [
        "## Model performance comparison and choosing the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TF1WfZZHbp1E"
      },
      "outputs": [],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        gbm_train_perf.T,\n",
        "        xgb2_train_perf.T,\n",
        "        ada_train_perf.T,\n",
        "        rf2_train_perf.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\n",
        "    \"Gradient Boosting tuned with oversampled data\",\n",
        "    \"XGBoost tuned with oversampled data\",\n",
        "    \"AdaBoost tuned with oversampled data\",\n",
        "    \"Random forest tuned with undersampled data\",\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0FgTXpsXbp1F"
      },
      "outputs": [],
      "source": [
        "# validation performance comparison\n",
        "\n",
        "models_val_comp_df = pd.concat(\n",
        "    [\n",
        "        gbm_val_perf.T,\n",
        "        xgb2_val_perf.T,\n",
        "        ada_val_perf.T,\n",
        "        rf2_val_perf.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_val_comp_df.columns = [\n",
        "    \"Gradient Boosting tuned with oversampled data\",\n",
        "    \"XGBoost tuned with oversampled data\",\n",
        "    \"AdaBoost tuned with oversampled data\",\n",
        "    \"Random forest tuned with undersampled data\",\n",
        "]\n",
        "print(\"Validation performance comparison:\")\n",
        "models_val_comp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrjMsivy4SVR"
      },
      "source": [
        "- The best validation recall score is 88.5% and obtained for XGBoost tuned with oversampled data and Randomforest with undersampled data.\n",
        "- But the validation precision is very low at the same time,which will result in increased inspection cost.\n",
        "- So, we will choose AdaBoost tuned with oversampled data as the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYS5m_mcbp1F"
      },
      "source": [
        "**Now we have our final model, let's find out how our model is performing on unseen test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qrWw_SWBkJtV"
      },
      "outputs": [],
      "source": [
        "# Let's check the performance on test set\n",
        "ada_test = model_performance_classification_sklearn(tuned_ada, X_test, y_test)\n",
        "ada_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG0fat-Mbp1F"
      },
      "source": [
        "\n",
        "- Let's check feature importance for AdaBoost classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tlY4dfMuVBUz"
      },
      "outputs": [],
      "source": [
        "feature_names = X_train.columns\n",
        "importances = tuned_ada.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGp5kg13bp1F"
      },
      "source": [
        "- V30 is most important feature followed by V9 and V18."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gohwGn0tbp1L"
      },
      "source": [
        "## Let's use Pipelines to build the final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGYtuiy21uQf"
      },
      "source": [
        "- Since we have only one datatype in the data, we don't need to use column transformer here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xTB5oErrbp1L"
      },
      "outputs": [],
      "source": [
        "Pipeline_model = Pipeline(\n",
        "   steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\n",
        "            \"AdaBoost Classifier\",\n",
        "             AdaBoostClassifier(\n",
        "                random_state=1,\n",
        "                learning_rate=0.2,\n",
        "                n_estimators=200,\n",
        "                base_estimator= DecisionTreeClassifier(max_depth=3, random_state=1),\n",
        "            ),\n",
        "       ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KVhk_Ga4bp1L"
      },
      "outputs": [],
      "source": [
        "# Separating target variable and other variables\n",
        "X1 = data.drop(columns=\"Target\")\n",
        "Y1 = data[\"Target\"]\n",
        "\n",
        "# Since we already have a separate test set, we don't need to divide data into train and test\n",
        "\n",
        "X_test1 = df_test.drop([\"Target\"], axis=1)\n",
        "y_test1 = df_test[\"Target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "esCUwy3ibp1L"
      },
      "outputs": [],
      "source": [
        "# We can't oversample data without doing missing value treatment, so let's first treat missing values in train set\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X1 = imputer.fit_transform(X1)\n",
        "\n",
        "# We don't need to impute missing values in test set as it will be done inside pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wRhGqGEqbp1M"
      },
      "outputs": [],
      "source": [
        "# Synthetic Minority Over Sampling Technique\n",
        "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
        "X_over1, y_over1 = sm.fit_resample(X1, Y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AWI12Lh5bp1M"
      },
      "outputs": [],
      "source": [
        "Pipeline_model.fit(X_over1, y_over1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vv4rUHXslMF2"
      },
      "outputs": [],
      "source": [
        "# Let's check the performance on test set\n",
        "Pipeline_model_test = model_performance_classification_sklearn(Pipeline_model, X_test, y_test)\n",
        "Pipeline_model_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdME3J172AN-"
      },
      "source": [
        "## Business Insights and Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxFmwam_bp1M"
      },
      "source": [
        "\n",
        "- The AdaBoost Classifier tuned using oversampled data has the best performance.\n",
        "- V30, V9 and V18 are the most important features. They can be deciphered to determine and analyze the actual variables to understand their impact on the predictive task at hand.\n",
        "- This model can be further used to detect if a wind turbine will fail or not and this will help reduce the cost.\n",
        "- We also saw that there might be few points near around the classification threshold(0.5 by default) which can be further studied by the engineer and a final call could be made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M7vease2bp1G"
      },
      "outputs": [],
      "source": [
        "# Find out probabilities and predictions on test set\n",
        "pred = tuned_ada.predict(X_test)\n",
        "prob = tuned_ada.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8EQ70P6Sbp1G"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe for the predicted, original and probabilities predicted by model\n",
        "result = pd.DataFrame(\n",
        "    np.transpose([y_test, pred, prob[:, 1]]),\n",
        "    columns=[\"Original\", \"Predicted\", \"Probability\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h2a6N_s9bp1G"
      },
      "outputs": [],
      "source": [
        "# Let's add label of FN, FP, TP, TN based on predicted values\n",
        "\n",
        "\n",
        "def Label(df):\n",
        "    if (df[\"Predicted\"] == 0) & (df[\"Original\"] == 0):\n",
        "        return \"TN\"\n",
        "\n",
        "    elif (df[\"Predicted\"] == 1) & (df[\"Original\"] == 1):\n",
        "        return \"TP\"\n",
        "\n",
        "    elif df[\"Predicted\"] > df[\"Original\"]:\n",
        "        return \"FP\"\n",
        "\n",
        "    elif df[\"Predicted\"] < df[\"Original\"]:\n",
        "        return \"FN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cx9sx2PUbp1G"
      },
      "outputs": [],
      "source": [
        "result[\"Label\"] = result.apply(Label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WCsJz-Zfbp1G"
      },
      "outputs": [],
      "source": [
        "# This is the final dataframe, which we can use to see if some pattern exists\n",
        "result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-SavBmZobp1K"
      },
      "outputs": [],
      "source": [
        "# With the threshold being 0.50, there could be some point near to the threshold which could be misclassified by the model\n",
        "# but they could be later analyzed by the team to decide if we can take a call on those samples\n",
        "\n",
        "result[(result[\"Probability\"] > 0.45) & (result[\"Probability\"] < 0.5)][\n",
        "    \"Label\"\n",
        "].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ll2jySbp1K"
      },
      "source": [
        "- If the threshold would have been 0.45 instead of 0.5, we will be able to classify 21 FN as TP and 2399 TN as FP\n",
        "- Changing the threshold can further help reduce the cost and such a call can be made by looking at probabilities at later stages, as changing the threshold directly might not help always."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v_-uuGqH-qTt",
        "xxhpZv9y-qTw",
        "4cVx5kZHbp02",
        "KQi5ygTC-qT1",
        "qlzqMR1K-qTz",
        "961px703qhLV",
        "5TcqcxbK-qT3",
        "Ch_TjRfF-qT5",
        "nUCorhch-qT4",
        "E3JYKVQubp06",
        "DhPuzWO7hmV8",
        "Lv7Bs8aUbp07",
        "3CjaGOdvbp08",
        "Bp8vC9MZbp09",
        "OzOa9FGA6WtG",
        "C91_6Swtbp1A",
        "fYLfDmHvbp1B",
        "Cg_OREBD1NOy",
        "2FtmPS7Ubp1D",
        "Dqj6dc38bp1E",
        "0uLE_tPV2Roq",
        "VbrQHwrKbp1C",
        "D9JNnpxa4jau",
        "gohwGn0tbp1L",
        "JdME3J172AN-",
        "JBRJIcuibp1F",
        "pGrfVKsobp1K"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}